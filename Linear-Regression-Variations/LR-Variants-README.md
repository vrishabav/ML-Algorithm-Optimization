# Linear Regression â€“ Optimization Methods

> **Scope:**
This repository contains the code and datasets used for implementations of the Adam, ADMM, Stochastic Quasi-Newton and Sub-sampled Hessian Free methods for optimizing linear regression (in addition to SGD)


## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ data/                                                        # Contains the datasets
â”œâ”€â”€ LR-Variants-README.md                                        # Overview and running guidelines
â”œâ”€â”€ Linear Regression Variants and Optimizations: Report.pdf     # Full report with analysis and conclusions
â”œâ”€â”€ algorithms.ipynb                                             # Jupyter Notebook containing algorithm implementations
â”œâ”€â”€ convergence_visualization.png                                # Visualization output of convergence analysis
â””â”€â”€ test_results.md                                              # Documentation of test results
```

## ğŸ“¦ Installation & Dependencies

Python modules used: numpy, pandas, matplotlib

---

## â–¶ï¸ Running the Code

While running the code trough command line or using the notebook, make sure all the datasets (diamonds_train, diamonds_val and diamonds_test - which can all be installed from the Data folder) are in the same directory as the .py/.ipynb
(ensure all the modules mentioned in the previous section are also installed while running - a command has been included for the same in the ipynb)

### Command-line

Run this command first:
```pip install -q pandas numpy matplotlib```
Then after navigating to the directory which contains the datasets and the .py file:
```python3 da24b033_submission.py```

---

## You can further add your own sections/titles along with corresponding contents here:

---

## ğŸ§¾ Authors

**Vrishab Anurag Venkataraghavan, DA24B033**, IIT Madras (2025â€“26)

